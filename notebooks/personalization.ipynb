{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPTei4aIkjP3K3Eyyr0juwX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rabbitmetrics/personalize-LLMs/blob/main/notebooks/personalization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8e4T7xQeDQz8"
      },
      "outputs": [],
      "source": [
        "!pip install -qU \\\n",
        "  python-dotenv==1.0.0 \\\n",
        "  langchain==0.0.313 \\\n",
        "  tiktoken==0.5.1 \\\n",
        "  openai==0.28.1 \\\n",
        "  klaviyo-api==5.2.0 \\\n",
        "  ShopifyAPI==12.3.0 \\\n",
        "  redis==5.0.1 \\\n",
        "  pandas-gbq==0.19.2 \\\n",
        "  Faker==19.12.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load environment variables from .env file\n",
        "\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "v5ulxlWnDglG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Redis database (redis.com) with redis-py\n",
        "\n",
        "import redis\n",
        "from langchain.vectorstores.redis import Redis\n",
        "\n",
        "url=os.getenv('REDIS_URL')\n",
        "\n",
        "host=os.getenv('REDIS_HOST')\n",
        "password=os.getenv('REDIS_PASSWORD')\n",
        "port=int(os.getenv('REDIS_PORT'))\n",
        "\n",
        "\n",
        "r = redis.Redis(\n",
        "  host=host,\n",
        "  port=port,\n",
        "  password=password)"
      ],
      "metadata": {
        "id": "M8X8h0iHDlE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check redis connection\n",
        "\n",
        "r.ping()\n",
        "\n"
      ],
      "metadata": {
        "id": "fDOpsq-3DoYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if anything is stored in the database, flush if needed\n",
        "\n",
        "r.keys()\n",
        "#r.flushdb() # in case you need to delete the data again"
      ],
      "metadata": {
        "id": "CPhrtcmNDt37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Shopify Product Data to Redis: Building The Retriever"
      ],
      "metadata": {
        "id": "pLizBM-ND3d9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generic functions used for extracting data from Shopify REST API\n",
        "\n",
        "import os\n",
        "import shopify\n",
        "import pandas as pd\n",
        "\n",
        "token = os.getenv('SHOPIFY_TOKEN')\n",
        "merchant= os.getenv('SHOPIFY_MERCHANT')\n",
        "\n",
        "api_session = shopify.Session(merchant,'2023-04', token)\n",
        "shopify.ShopifyResource.activate_session(api_session)\n",
        "\n",
        "def get_data(object_name):\n",
        "    all_data=[]\n",
        "    attribute=getattr(shopify,object_name)\n",
        "    data=attribute.find(since_id=0, limit=250)\n",
        "    for d in data:\n",
        "        all_data.append(d)\n",
        "    while data.has_next_page():\n",
        "        data=data.next_page()\n",
        "        for d in data:\n",
        "            all_data.append(d)\n",
        "    return all_data\n",
        "\n",
        "def product_frame(products):\n",
        "    all_products=[]\n",
        "    for product in products:\n",
        "        p=product.attributes\n",
        "        record={k: p.get(k, None) for k in ('id', 'title','vendor','body_html','handle','status','tags')}\n",
        "        record['price']=p['variants'][0].attributes['price']\n",
        "        all_products.append(record)\n",
        "    df=pd.DataFrame(all_products)\n",
        "    return df"
      ],
      "metadata": {
        "id": "bqoWI2uQDy9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract product data from Shopify (or json file) and transform into a suitable format for vector storage.\n",
        "# A sample of Shopify products can be found on https://github.com/rabbitmetrics/personalize-LLMs\n",
        "\n",
        "products=get_data('Product')\n",
        "frame=product_frame(products)\n",
        "\n",
        "#frame.reset_index(drop=True).to_json('products.json',orient='records')\n",
        "#frame=pd.read_json('products.json')\n",
        "\n",
        "\n",
        "max_text_length=800\n",
        "def truncate_text(text):\n",
        "    return text[:max_text_length]\n",
        "frame['body_html']=frame.apply(lambda row: truncate_text(row['body_html']),axis=1)\n",
        "\n",
        "product_data=frame.reset_index(drop=True).to_dict(orient='index')\n",
        "\n",
        "texts = [\n",
        "    v['title'] for k, v in product_data.items()\n",
        "]\n",
        "\n",
        "metadatas = list(product_data.values())"
      ],
      "metadata": {
        "id": "COmfH4CtD9tI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load OpenAI embeddings, you can also use HuggingFace embeddings by pip installing SentenceTransformers\n",
        "\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "RSR9Vu41EFTp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Redis and load vector data from LangChain\n",
        "\n",
        "from langchain.vectorstores.redis import Redis\n",
        "\n",
        "vector_schema = {\"algorithm\": \"HNSW\",\"initial_cap\": 400}\n",
        "\n",
        "rds = Redis.from_texts(\n",
        "    texts,\n",
        "    embeddings,\n",
        "    metadatas=metadatas,\n",
        "    redis_url=url,\n",
        "    index_name=\"shopify_products\",\n",
        "    vector_schema=vector_schema,\n",
        "\n",
        ")\n",
        "\n",
        "# check that vector data has been added\n",
        "r.keys()"
      ],
      "metadata": {
        "id": "DUzgP5HcEH6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To delete the products from the database run\n",
        "#for key in r.scan_iter(\"doc:shopify_products:*\"):\n",
        "#  r.delete(key)"
      ],
      "metadata": {
        "id": "nj9uCaPuER7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that we can do VSS\n",
        "docs=rds.similarity_search(\"Adidas shoes\", 5)\n",
        "docs"
      ],
      "metadata": {
        "id": "OKSa7-szEAfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write the schema to a yaml file and use it to connect the existing index from another instance\n",
        "\n",
        "rds.write_schema(\"redis_schema.yaml\")"
      ],
      "metadata": {
        "id": "ziGiqevAEfr3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Personalization Data to BigQuery"
      ],
      "metadata": {
        "id": "dq99JWIpEnD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import datetime\n",
        "from faker import Faker\n",
        "import random\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "import pandas_gbq"
      ],
      "metadata": {
        "id": "6BbD44PzEjrI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incentives = ['bogo','free_shipping','special_offer','free_gift','10% discount','no_incentive']\n",
        "\n",
        "faker = Faker()\n",
        "domain='your_domain' # you can just add some id instead that can be used as a primary key\n",
        "\n",
        "def customer_frame():\n",
        "    ict=[random.choice(incentives) for i in range(100)]\n",
        "    df=pd.DataFrame(ict,columns=['incentive'])\n",
        "    df['feature_timestamp']=df.apply(lambda row: datetime.datetime.now()-datetime.timedelta(hours=2), axis=1)\n",
        "    df['created']=df.apply(lambda row: datetime.datetime.now()-datetime.timedelta(hours=2),axis=1)\n",
        "    df['first_name']=df.apply(lambda row: faker.first_name(), axis=1)\n",
        "    df['last_name']=df.apply(lambda row: faker.last_name(), axis=1)\n",
        "    df['email']=df.apply(lambda row:\n",
        "                     row['first_name'].lower()+row['last_name'].lower()+domain,\n",
        "                     axis=1)\n",
        "    df = df[['email', 'first_name', 'last_name', 'incentive', 'created','feature_timestamp']]\n",
        "    return df\n",
        "\n",
        "feature_frame=customer_frame()"
      ],
      "metadata": {
        "id": "aTvKAxQCEsns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "table_id='table_name.dataset_name'\n",
        "project_id=\"your_gcp_project\"\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    'service_account_json_key',\n",
        ")\n",
        "\n",
        "pandas_gbq.context.credentials = credentials\n",
        "pandas_gbq.context.project = project_id\n",
        "\n",
        "pandas_gbq.to_gbq(feature_frame, table_id, project_id=project_id)"
      ],
      "metadata": {
        "id": "JbOL7uPWEvLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Feast with BigQuery and Redis"
      ],
      "metadata": {
        "id": "id-4Hr8lFaOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Feast. We'll be using BigQuery as offline store and Redis as online store\n",
        "\n",
        "! pip install -qU 'feast[gcp, redis]'"
      ],
      "metadata": {
        "id": "O-_m55WHFXfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a feature repo allowing us to connect to GCP - choose some appropriate name\n",
        "\n",
        "! feast init langchain_klaviyo -t gcp"
      ],
      "metadata": {
        "id": "yD63DNENVTER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change dir to where the feature_store.yaml file is located\n",
        "# Configure the yaml file and the example_repo.py file. Example setup of these files are found on https://github.com/rabbitmetrics/personalize-LLMs\n",
        "\n",
        "%cd langchain_klaviyo/feature_repo/"
      ],
      "metadata": {
        "id": "By-uQBVEFf2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set application credentials using the json key created on GCP. Move or copy the json key to the current folder first.\n",
        "\n",
        "import os\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"./klaviyo.json\""
      ],
      "metadata": {
        "id": "76GX1bbMFnbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply configuations\n",
        "\n",
        "! feast apply"
      ],
      "metadata": {
        "id": "XRck2QMvFtlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Materialize features (changes) from offline store to online store\n",
        "\n",
        "!feast materialize-incremental $(date -u +\"%Y-%m-%dT%H:%M:%S\")"
      ],
      "metadata": {
        "id": "Vb2wjGKfGGQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that features have been materialized to Redis\n",
        "\n",
        "r.keys()"
      ],
      "metadata": {
        "id": "1Slcp26oJnQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import FeatureStore that allows us to extract the features\n",
        "\n",
        "from feast import FeatureStore\n",
        "\n",
        "\n",
        "feast_repo_path = \"./\"\n",
        "store = FeatureStore(repo_path=feast_repo_path)"
      ],
      "metadata": {
        "id": "HV1z3mJ5Jp2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create function that extracts features for a particular customer\n",
        "\n",
        "def get_feature(email):\n",
        "    f=store.get_online_features(\n",
        "        features=[\n",
        "        \"incentives:incentive\",\n",
        "        \"incentives:first_name\",\n",
        "        \"incentives:last_name\",\n",
        "    ],\n",
        "        entity_rows=[{\"email\": email}]\n",
        "    ).to_dict()\n",
        "    return f"
      ],
      "metadata": {
        "id": "csRkJgAMJ4xu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_feature()"
      ],
      "metadata": {
        "id": "XnB0g9w7J5RG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Injecting Features into LangChain Prompt Templates"
      ],
      "metadata": {
        "id": "sQGUGvE9KItH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import PromptTemplate, StringPromptTemplate\n",
        "\n",
        "\n",
        "from langchain.chains.summarize import load_summarize_chain"
      ],
      "metadata": {
        "id": "ffH3TW_0KHD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat=ChatOpenAI(model_name=\"gpt-4\", temperature=0.2)"
      ],
      "metadata": {
        "id": "Ol12rl8BKOA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Entire Email template\n",
        "\n",
        "base_template = \"\"\"\n",
        "\n",
        "You are an email writing assistant that wants to convert customers based on the information given.\n",
        "Take the customer data into account when formulating an email.\n",
        "\n",
        "\n",
        "Here is the data on the customer including what type of incentive we think the customer prefers:\n",
        "\n",
        "\n",
        "<customer_data>\n",
        "\n",
        "Recommended incentive: {incentive}\n",
        "\n",
        "</customer_data>\n",
        "\n",
        "Use the recommended incentive to craft an offer but don't mention the incentive explicitly in the email.\n",
        "\n",
        "Relevant products: {text}\n",
        "\n",
        "Email is from team Running Customer\n",
        "\n",
        "Your response:\"\"\"\n",
        "base_prompt = PromptTemplate.from_template(base_template)"
      ],
      "metadata": {
        "id": "e-vNIt74KQcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you only need a few lines to load to Klaviyo\n",
        "\n",
        "base_template = \"\"\"\n",
        "\n",
        "You are an email writing assistant that wants to convert customers based on the information given.\n",
        "\n",
        "Write 3 sentences that can be used in a marketing email targeting the specific customer. Take the recommended\n",
        "incentive given in the \"customer data\" section into account when formulating the paragraph.\n",
        "\n",
        "\n",
        "Here is the data on the customer including what type of incentive we think the customer prefers:\n",
        "\n",
        "\n",
        "<customer_data>\n",
        "\n",
        "Recommended incentive: {incentive}\n",
        "\n",
        "</customer_data>\n",
        "\n",
        "Use the recommended incentive to craft an offer but don't mention the incentive explicitly in the email.\n",
        "\n",
        "Relevant products: {text}\n",
        "\n",
        "No need for signature as this will be pasted into an email template\n",
        "\n",
        "Your response:\"\"\"\n",
        "base_prompt = PromptTemplate.from_template(base_template)"
      ],
      "metadata": {
        "id": "XnUrqkxAKSeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create customized prompt template with feature data\n",
        "\n",
        "class FeastPromptTemplate(StringPromptTemplate):\n",
        "    def format(self, **kwargs) -> str:\n",
        "        email = kwargs.pop(\"email\")\n",
        "        feature_vector = store.get_online_features(\n",
        "            features=[\n",
        "                \"incentives:incentive\",\n",
        "                \"incentives:first_name\",\n",
        "                \"incentives:last_name\",\n",
        "            ],\n",
        "            entity_rows=[{\"email\": email}],\n",
        "        ).to_dict()\n",
        "        kwargs[\"incentive\"] = feature_vector[\"incentive\"][0]\n",
        "        return base_prompt.format(**kwargs)"
      ],
      "metadata": {
        "id": "pn9chHffKU_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_prompt_template = FeastPromptTemplate(input_variables=[\"email\",\"text\"])"
      ],
      "metadata": {
        "id": "g_zAJQzlKXjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_prompt_template.format(email=\"davidhill@mg.rabbitpromotion.com\",text=\"adidas shoes\"))"
      ],
      "metadata": {
        "id": "z70nci0WKFpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create summarize chain with GPT-4 and customized feature prompt template\n",
        "\n",
        "chain = load_summarize_chain(chat, chain_type=\"stuff\", prompt=feature_prompt_template)\n",
        "response=chain({\"input_documents\": docs,\"email\": \"some_email\"},return_only_outputs=False)\n",
        "\n",
        "print(response['output_text'])"
      ],
      "metadata": {
        "id": "LPRNzqaaJ-H4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Chatbot\n",
        "We can use the same feast+redis backend to feed a chatbot with customer features. This allows for personalization of all interactions with customers. If the pipeline to Redis through Feast is set up to be event-driven this allows for real-time contextualization."
      ],
      "metadata": {
        "id": "1sX6QU0qKhrr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create template that allows for both feature injection and customer interaction\n",
        "\n",
        "base_template = \"\"\"\n",
        "\n",
        "You are a conversational ecommerce shopping assistant that wants to convert the customer based on\n",
        "the information given.\n",
        "\n",
        "\n",
        "Here is the data on the customer including what type of incentive we think the customer prefers:\n",
        "\n",
        "\n",
        "<customer_data>\n",
        "\n",
        "Recommended incentive: {incentive}\n",
        "\n",
        "</customer_data>\n",
        "\n",
        "\n",
        "Human: {question}\n",
        "\n",
        "Relevant products: {context}\n",
        "\n",
        "\n",
        "\n",
        "Your response:\"\"\"\n",
        "base_prompt = PromptTemplate.from_template(base_template)"
      ],
      "metadata": {
        "id": "gAK4DA7SKi3M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Template used for condensing the question and chat history\n",
        "\n",
        "template=\"\"\"\n",
        "Use the follow up input {question}, and the chat history {chat_history} to formulate a standalone question.\n",
        "\"\"\"\n",
        "condense_question_prompt = PromptTemplate.from_template(template)"
      ],
      "metadata": {
        "id": "YU35poTbKtcS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll use ConversationalRetrievalChain with streaming output for the chatbot\n",
        "\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.callbacks.manager import AsyncCallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler"
      ],
      "metadata": {
        "id": "zhdgLPnJKv5H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_prompt_template = FeastPromptTemplate(input_variables=[\"email\",\"question\",\"context\"])"
      ],
      "metadata": {
        "id": "lCy3wO74Kyc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the chatbot using ConversationalRetrievalChain - note that the feature prompt template is passed as kwargs.\n",
        "\n",
        "chatbot = ConversationalRetrievalChain.from_llm(\n",
        "    ChatOpenAI(temperature=0,\n",
        "               model=\"gpt-4\",\n",
        "               streaming=True,\n",
        "               callbacks=AsyncCallbackManager([\n",
        "               StreamingStdOutCallbackHandler()\n",
        "    ]),\n",
        "              ),\n",
        "    rds.as_retriever(),\n",
        "    condense_question_prompt = condense_question_prompt,\n",
        "    condense_question_llm = ChatOpenAI(temperature=0, model='gpt-4'),\n",
        "    combine_docs_chain_kwargs=dict(prompt=feature_prompt_template),\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "-bOMQDzTK0kI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(feature_prompt_template.format(email=\"some_email\",question=\"looking for shoes\",context=\"adidas\"))"
      ],
      "metadata": {
        "id": "iYbQ4W83K2wC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chat_history = []\n",
        "query = \"I'm looking for somme cool kids sneakers\"\n",
        "result = chatbot({\"question\": query,\"email\":\"some_email\", \"chat_history\": chat_history})"
      ],
      "metadata": {
        "id": "llUGv7cFK5Ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9ANBTVUfK7m1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}